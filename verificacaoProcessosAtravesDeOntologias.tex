%TO DO LIST
%CHECK EMAIL
%CHECK PLACEHOLDERS
%FILL CITATION
%CHECK REVIEWS
%EVERTHING GREEN
%CHECK INDENT AFTER SECTION TITLES
\documentclass[a4paper,twoside]{article}

\usepackage[utf8]{inputenc} 
%\usepackage{mathptmx}
%\usepackage{textcomp}
 \usepackage{multirow}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{calc}
\usepackage{amssymb}
\usepackage{amstext}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage{pslatex}
\usepackage{apalike}
\usepackage{SCITEPRESS}     % Please add other packages that you may need BEFORE the SCITEPRESS.sty package.

\subfigtopskip=0pt
\subfigcapskip=0pt
\subfigbottomskip=0pt

\begin{document}

\title{A Semiautomatic Process Model Verification Plug-in based on Process Modeling Guidelines}
%FIXEMAIL
\author{\authorname{Valter Helmuth Goldberg Júnior\sup{1}, Lucineia Heloisa Thom\sup{1} and Diego Toralles Avila\sup{1}}
	\affiliation{\sup{1}Department of Informatics, Federal University of Rio Grande do Sul, UFRGS, Porto Alegre, Brazil}
	\email{\{EMAILDOWALTER,lucineia,dtavila\}@inf.ufrgs.br}
}

\keywords{The paper must have at least one keyword. The text must be set to 9-point font size and without the use of bold or italic font style. For more than one keyword, please use a comma as a separator. Keywords must be titlecased.}

%TODO
\abstract{The abstract should summarize the contents of the paper and should contain at least 70 and at most 200 words. The text must be set to 9-point font size.}

\onecolumn \maketitle \normalsize \vfill

\section{INTRODUCTION} \label{Introduction}

%What is BPM
%DONE?
\noindent Business Process Management (BPM) is a discipline that provides a systematic approach to manage an organization's work by modeling, analyzing, improving and controlling its business processes (hereafter called processes, for simplification). It contributes to the increase of productivity and reduction of costs through more effective, more efficient and more adaptable processes \cite{aalst:2013}. %As such, we are increasingly worried about the quality of our processes, as we base the value of a business on top of the models generated by the modeling of our processes in BPM.

%FIX REFERENCES
Through the use of BPM, organizations continually seek to improve the quality of their processes. However, studies analyzing industry process model collections reveal that many models contain issues that harm its quality, such as control flow errors, badly designed structures and layouts or incorrect labeling \cite{Detection and Prediction of Errors in EPCs of the SAP Reference Model.} \cite{What we can learn from Quality Issues of BPMN Models from Industry}. With process modeling being a key part of BPM, it is important that we try to prevent these issues if we are to have processes of better quality.

%Model and Modeling - To work with process we need a model of said process. Modeling is a fundamental task in BPM.
%Problem - Modeling is hard and not objective. Some models are better than others
%I have to point out that many models are badly created, that this is an actual problem in reality, not that "Modeling is hard". Instead, let this paragraph tell WHY modeling is hard.
%ALSO, "Modeling" or "Modelling". This paper will be presented on the EU (I think), which spelling is commonly used there?

%FIX REFERNECE
It is widely accepted that modeling a process is difficult \cite{7PMG}. This is usually due to the complexity of the modeling notation, its many different elements and their respective semantics \cite{What we can learn from Quality Issues of BPMN Models from Industry}. Choosing the appropriate representation depends upon the expertise or the guidance of an experienced modeler, which can greatly influence the quality of the resultant model. While the use of process modeling tools can help in this regard, they cannot guarantee a model's correctness nor its comprehensibility.


%Guidelines - There are "rules of thumb" to modeling. We want to verify said rules with some formality.
%guidelines "solve" the quality challenge, they do reduce complexity and prevent errors, they are many, etc, BUT their use is not that widespread, especially in professional tools.

One way to solve this challenge and help beginner modelers is to consolidate the knowledge of experienced modelers into process modeling guidelines, whose purpose is to help the user reduce the complexity and the number of errors in a process model by restricting undesirable constructs from being introduced. Many guidelines have been proposed by both practitioners \cite{Silver2009} \cite{White2008} \cite{Allweyer2010} and researchers \cite{Becker2000} \cite{Mendling2007} \cite{Vanderfeesten2008} \cite{Correia2012}. Once it is verified that a process model is following a set of guidelines, we can assume that it has good comprehensibility.

%Syntax before comprehensibility
However, using guidelines to verify a process model doesn't make sense if it isn't syntactically correct. Any knowledge extracted from an incorrect process model has its validity compromised because, while you may be able to understand it, you may doubt whether it is what the modeler intended to portray \cite{Reijers2015}. Therefore, one must check if a process model is correct before considering it's comprehensibility.


%Ontology - Verifies correctness
It is possible to verify the correctness of process models through different ways. One of these is by the means of ontologies, which has seen wide-spread use in research on information science. Ontology is the study of being, which seeks to represent the world in entities, categories and relations \cite{Mendling2008}. In a more practical setting, an ontology provides an approach to define types, properties and relations. Given this, we can an ontology for process models as a meta-model to verify any process model correctness.


%Hypothesis and %Objectives
Along these lines, the purpose of this paper is to show how the use of ontologies may assist in the identification of problems that reduce a process model comprehensibility. To do that, it is necessary to input a process model into a process model ontology and, after that, verify it using a set of process modeling guidelines, pointing out any problems in the model that can be improved upon.


%PaperStructure
%TODO
This paper is organized as follows: Section \ref{RelatedWorks} outlines previous works related to the verification of process models. Section \ref{Background} shortly introduces the basic concepts used in this paper. Section \ref{Methodology} displays PLACEHOLDER. Section \ref{CaseStudy} presents our case study and our results. Section \ref{Conclusion} closes the paper with our conclusions.

\section{RELATED WORKS}\label{RelatedWorks}

%Verification Works

%Through Correctness
\noindent The verification of business process models is nothing new, in fact, there have been numerous papers and books published that address this. The difference is that most of these publications are concerned with issues of correctness of a process model. In \cite{Mendling2008}, for example, the author proposes two different approaches to verifying soundness of a process model draw using Event-Process-Chains.
	
%Through Metrics 
Evaluating and reducing the complexity of a process model, though, is harder to achieve. It is not possible to measure a process complexity directly and, because of this, many metrics have been proposed that try this indirectly \cite{Quality metrics for business process models} \cite{MetricsForProcessModels} \cite{Complexity metrics for business process models}. The validity of these metrics is evidenced through statistical experiments, where models are judged both by the metrics and by people with varying levels of modeling experience \cite{Process control-flow complexity metric: An empirical validation} \cite{Prediction of business process model quality based on structural metrics}.

%Through Guidelines
As it was mentioned before, many authors have proposed guidelines for modeling business processes, so many that it is likely they repeat guidelines already proposed, with only few small variations in the details. In \cite{Moreno-MontesdeOca2014}, these repeats were gathered from a systematic review about business process modeling quality from over a 100 proposed in the literature and turned into 27 unified guidelines.  

%REFERNECE FOR SIGNAVIO
Some of the existing BPMN tools try to provide some support for creating good process models. Based on the guidelines found in the previous article, a study \cite{MoniqueSnoeckIsel2015} was performed to test how extensive was, at the time, the support of the popular BPMN tools in creating good models. From this, we can learn that the Signavio \footnote{www.signavio.com} modeler tool provides the best amount of support for modeling processes using guidelines. 


\section{BASIC NOTIONS}\label{Fundamentals}\label{Background}

%Modeling %BPMN %Problems
%IMPROVE? Should I insert BPMN element types?
\noindent The modeling task of BPM is often done using the Business Process Model and Notation (BPMN). BPMN was developed by the Object Management Group (OMG), with the purpose of consolidating the many existing notations for process models in a single standard. This standard should provide a easy to comprehend notation to all stakeholders \cite{OMGObjectManagementGroup2015}. However, BPMN does not teach modelers how to use it's elements in the creation of simple and expressive process models. The consequence of this is that it's hard to achieve a a good level of quality in BPMN process models.


%Qualities
%REFERENCES
This difficulty motivated the creation of many frameworks that try to define what a process model quality is and classify the different quality types that compose it. Examples of these are the SEQUAL Framework, the Guidelines of Modeling (GoM) and, more recently, the SIQ framework, in which we base this work upon. The SIQ framework defines process model quality as factor of three basic quality types:

%REFERENCE OF SOUND
\begin{itemize}
	\item \textbf{Syntactic Quality} identifies if a process model conforms to the rules defined by the notation used to create it. In other words, if a process model follows the syntax and the vocabulary of its modeling language, we can verify that process model and declare it correct. To do so, the verification must check the static proprieties of a process model - how different types of elements are used and combined - and its behavioral proprieties - the process modeled should not reach a deadlock and must be completed properly, i.e the process model is \textit{sound}.
	\item \textbf{Semantic Quality} bears the connection between a process model and the real world process it's supposed to represent. Checking a process model's semantic quality is, basically, making sure it is valid - all elements of the process model correctly represent the real world - and complete - there are no real world process parts that are missing in the process model. This check is simply called validation and, if it passes, the process model is determined true.
	\item \textbf{Pragmatic Quality} characterizes the comprehensibility of a process model. It is the certification that a user's interpretation of a process model is equal to the actual, real world process. If done so, the process model is said to be understood.
\end{itemize}

%Syntactic is basis for the others
%INSERT PICTURE
Syntactic quality is the basis for the other two qualities. As mentioned before, it is not sensible to consider the comprehensibility of a process model if it is not syntactically correct. The same can be said of its semantic quality. As such, the verification of a process model must be done before its validation or certification.

%TODO - Mention OWL?
%BPMN Ontology
As previously explained, it's possible to do this verification using an ontology. More specifically, we can use an ontology design to serve as a meta-model for a process modeling notation. In the case of BPMN, there exists what is called the \textit{BPMN Ontology} \cite{Rospocher2014foisbpmn}, which supports the mapping of a BPMN process model into elements of the ontology, while preserving the relations and strutures between the process model elements. Then, we can use an inference engine to verify the mapped model, which will check if the static propreties of BPMN model, , i.e its structure, is correct according to the BPMN syntax.


%To verify these guidelines, we need to transform the model from the BPMN standard into a more formal one, which in this case is an ontology, because, in computer science, the most common definition of an ontology is an explicit and formal specification of a shared conceptualization \cite{borst1997ontology, Gruber1995907, Studer1998161}. The transformation between BPMN and an ontology is done through the use of the already existing \textit{BPMN Ontology} \cite{Rospocher2014foisbpmn}. This allows us to verify the process model, or more precisely its structure, through the use of an ontological reasoner. 
%The Table \ref{BPMNOntologyMapping} shows how the mapping is done.




%Guidelines
%SHOULD I go into more detail about what a guideline is?
%7PMG
Finally, assuming the process model is indeed correct, we can try yo ensure its pragmatic quality, which, in this case, is done by checking via the use of process modeling guidelines.  In \cite{Mendling2010}, seven process modeling guidelines (7PMG) have been proposed that are "thought to be helpful in guiding users towards improving the quality of their models, in the sense that these are likely (1) to become comprehensible to various stakeholders and (2) to contain few syntactical errors". These guidelines have been built upon empirical insights and, as such, provide a short but meaningful set of rules. They are as follows:
\begin{enumerate}
	\item[G1] Use as few elements in the model as possible.
	\item[G2] Minimize the routing paths per element.
	\item[G3] Use one start and one end event.
	\item[G4] Model as structured as possible. 
	\item[G5] Avoid OR routing elements.
	\item[G6] Use verb-object activity labels.
	\item[G7] Decompose a model with more than 50 elements.
\end{enumerate}

%SWTICH NAME
\section{METHODOLOGY}\label{Methodology}


\noindent To fulfill the purpose of this paper, we must define a series of steps that, with the assistance of an ontology, allows us check a process model's pragmatic quality by verifying whether it follows Mendling's seven process modeling guidelines. However, before we can do this, there are a few things we must define. 

To start with, we must decide how are the process models going to be represented. A few different notations for process models exist and each notation has different ways of how the model is coded within a file. As can be implied from the previous section, the notation used in this work is BPMN 2.0. Models using this notation can be exported into the interchangeable format defined by OMG, which is simply a XML file with a specific schema and a .bpmn extension \cite{OMGObjectManagementGroup2015}. From this file, we can easily map elements from the model into the an ontology, via the \textit{BPMN Ontology}.

Secondly, we need to establish how we are going to check whether or not a guideline is being followed or not by a model. We must express them in such a way that they turn into a yes or no question. To do that, for each guideline must be related to a metric that can measure and compare a model against supposed optimal values. Based upon previous works \cite{Mendling2008} \cite{recker2011evaluations} \cite{Mendling:2012}, the table \ref{Metrics} presents the metrics and optimal values utilized to check if the model violates each guideline.

\begin{table}[]
	\centering
	\caption{Parameters tested for each guideline from 7PMG}
	\label{Metrics}
	\begin{tabular}{|c|c|}
		\hline
		7PMG & Metrics and Comparisons \\ \hline
		G1 & Number of Elements $>$ 30 \\ \hline
		G2 & Highest Element Degree $>$ 7 \\ \hline
		G3 & \begin{tabular}[c]{@{}c@{}}Number of StartEvents $>$ 1\\ Number of End Events $>$ 1\end{tabular} \\ \hline
		G4 & Number of Splits $\neq$ Number of Joins \\ \hline
		G5 & Number of OR Gateways $>$ 0 \\ \hline
		G6 & Wordnet \\ \hline
		G7 & Number of Elements $>$ 30 \\ \hline
	\end{tabular}
\end{table}

With these parameters, two guidelines show problems: G1 and G6.

%G1, the guideline for encouraging the use of less elements when modeling, becomes redundant with G7, which determines when a model should be decomposed. This happens because G1 is much more suited to be used when a model is being developed, when one can refrain from introducing a few elements instead of when the modeling is finished and the choice becomes of how the model can be decomposed. As a result, the metric measured for both guidelines is the same, requiring us to choose the more appropriate one for testing. In this case, since we are working with a model and not with modeling, the guideline G7 is more appropriate.

G1, the guideline for encouraging the use of less elements when modeling, becomes redundant with G7, which determines when a model should be decomposed. This happens because the metric used for G1 is the same as the one used for G7. Because of this, we need to choose which guideline is more appropriate for our method. Since G1 is more suited to be used when a model is being developed and the modeler can refrain from introducing a few elements, instead of when the modeling is finished, the guideline G7 is more appropriate.

G6, which tells us to label activities in the verb-object style, is the second problematic guideline. In this case, the problem is in the complexity of checking the language of each label. This exceeds the scope of this work, since it requires the use of Natural Language Processing to identify the words of each label and compare them and their use against a thesaurus to define the label's context \cite{gassen2014business}. Therefore, we are ignoring this guideline.

\begin{table*}[]
	\caption{BPMN $\Rightarrow$ Ontology Mapping}
	\label{bpmnOntologyMapping}
	\centering
	\begin{tabular}{| c |c |c |}
		\hline
		BPMN & Ontology & Example \\
		\hline
		Element Type & OWL Class & Activity, Gateway \\\hline
		Element Instance & Individual Named & Task 1: Submit Report \\  \hline
		Attribute & Object Property & Label="Name" \\\hline
		Attribute Value & Data Property & Name:String="Task 1: Submit Report" \\ 
		\hline
	\end{tabular} 
\end{table*}


Finally, we must determine how are we going to load and edit an ontology. We chose to use the ontology editor \textit{Protégé} \footnote{http://protege.stanford.edu/}. \textit{Protégé} not only can verify the integrity of ontologies using an inference engine, it is also easily extensible through the use of plugins. %Both features will be helpful in our method.

\subsection{Verifying Process Models Based on Process Modeling Guidelines}
\noindent Given the decisions made in this previous section, we can define a method to verify the process models. Our objective is to map and load BPMN models into an ontology using \textit{Protégé} and then checking those models using Mendling's guidelines.

The first step is simply to prepare \textit{Protégé} for instantiating BPMN models. To do this, we load BPMN ontology into the editor, so that it will support the mapping of elements from BPMN to the ontology by serving as the meta-model containing the structuring rules of BPMN.

Once that is done, we can begin extracting the individual elements from the BPMN models and instantiating each of them into the ontology. We developed a Java plugin for \textit{Protégé} which reads the .bpmn file of the process models and extracts its tasks, gateways, sequence flows and messages. After that, this same plugin uses the OWL-API to create individuals for each element, mapping and instantiating them according to each type described by the BPMN Ontology. The table \ref{bpmnOntologyMapping} shows how the mapping is done.

After this is completed, we can finally have the ontology assist us in checking the process model syntax.  Using \textit{Protégé} inference engine, we can verify the ontology's integrity. If this is successful, it can be assumed that the structure of the BPMN model mapped into Protégé is syntactically correct, since any syntactical error in the process model's structure would violate the ontology's integrity according to the BPMN Ontology.

The final steps of this method are checking the process model according Mendling's guidelines and recommending alterations based upon the results. We developed another Java Plugin that checks the process model's metrics and, for each violated guideline, the plugin recommends actions according to the table \ref{RecommendedActions}.

\begin{table}[]
	\centering
	\caption{Recommended Actions for each tested guideline}
	\label{RecommendedActions}
	\begin{tabular}{|c|p{5.5cm}|}
		\hline
		7PMG & Recommended Action \\ \hline
		G2 & Reduce the number of sequence flows connected to a single element \\ \hline
		G3 & Restructure the model to reduce the number of Start and End events \\ \hline
		G4 & Restructure the model to have the same number of Split and Joins \\ \hline
		G5 & Restructure the process model to remove the OR Gateways \\ \hline
		G7 & Decompose the process model \\ \hline
	\end{tabular}
\end{table}

The entire series of steps is as follow:

\begin{enumerate}
	\item Load the BPMN Ontology into \textit{Protégé}
	\item Extract each individual element from a BPMN model.
	\item Instantiate each extracted element into \textit{Protégé} via OWL-API and using the BPMN Ontology.
	\item Use \textit{Protégé}'s inference engine to verify the integrity of the new ontology.
	\item Check if the model's parameters obey the limits defined by the modeling guidelines.
	\item Recommend model alterations for each guideline not followed.
\end{enumerate}

%To verify the model according to the 7PMG, a plug-in for Protégé was developed, in which each guideline proposed had to be represented. For most guidelines (G1, G2, G3, G5, G7), we can do this using a simple test performed on top of a model's metrics. For G4, we simplify the guideline by measuring the number of splits and joins for each type of gateway. If that number is different then G4 has been disobeyed. Finally, G6 involves natural language processing for analyzing the syntax of each label, which is something outside of the scope of the work presented in this paper, therefore it has been left out. Table \ref{Metrics} shows each rule and associated metric being tested. Finally, the results of the verification are shown using a another plug-in in Protégé. The result of the test of each guideline is show with a "True" or "False" value.




\section{CASE STUDY AND RESULTS}\label{CaseStudy}

\noindent To validate our method, we applied it to a collection of 31 BPMN models. These are models of the the processes of a university, created by students of BPM, verified and corrected by their professor and semantically validated by each model's stakeholders. 

For each guideline used in our method, we extracted the related metrics for analysis via statistics. The tables \ref{MetricsExtracted} and \ref{MetricsGateways} show this. We can then use these statistics to predict whether most of the models of this collection follow or not the process modeling guidelines. 

\begin{table*}[]
	\centering
	\caption{Statistics for metrics related to the guidelines G2, G3, G5, G7}
	\label{MetricsExtracted}
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		& \begin{tabular}[c]{@{}c@{}}Highest \\ Connectivity Degree\end{tabular} & Nº Start Events & Nº End Events & Nº OR Gateways & Nº Elements \\ \hline
		Average & & 2.20513 & 2.25641 &  0.28125 & 24.79487 \\ \hline
		Std. Deviation & & 2.00236 & 1.96974 &  0.85135 & 17.71288 \\ \hline
		Minimum & & 1 & 1 &  0 & 6 \\ \hline
		Maximun & & 13 & 13 &  4 & 98 \\ \hline
		Median & & 2 & 2 &  0 & 21 \\ \hline
	\end{tabular}
\end{table*}

\begin{table}[]
	\centering
	\caption{Statistics for metrics related to the guideline G4}
	\label{MetricsGateways}
	\begin{tabular}{|c|c|c|c|}
		\hline
		\multirow{2}{*}{}  & \multicolumn{3}{c|}{Splits - Joins Difference} \\ \cline{2-4} 
		& AND            & XOR           & OR            \\ \hline
		Average            & 0.125          & 0.53125       & -0.09375      \\ \hline
		Std. Deviation & 0.33601   & 1.39085   & 0.39016   \\ \hline
		Minimum            & 0              & -2            & -2            \\ \hline
		Maximun            & 1              & 4             & 0             \\ \hline
		Median             & 0              & 0.5           & 0             \\ \hline
	\end{tabular}
\end{table}

%TODO G2
For example, in the statistics for Highest Connectivity degree, for guideline G2, we see... G5 is similar, since the average number of OR gateways is low, but not zero, and the standard deviation is almost 1, implying that a few models do use OR gateways, up to the maximum of 4. Because of this, we expect that a few process models do violate this guideline, and our method will show this.

For G3, on the other hand, the number of start and end events has the high average of more than 2 , compared to the recommended use of 1 event of each. This would imply that most process models from the collection do not follow G3. 

Analysis for guideline G4 is more complicated, since we measure the difference between the two metrics related to it. Not only that, we also have to measure this difference for each different type of gateway. We can, however, clearly see the imbalance of the number of XOR splits versus the number of XOR joins by looking at the average of that metric. That information, together with the high standard deviation show for each gateway, indicates that most process models in the collection are not structured.

The statistics for G7 are slightly vague. The high, but not unreasonable, average for the measure of the number of elements suggest that the guideline is followed. Yet, the high standard deviation hints that at least some models do have more than 30 elements.

With all this information in mind, our expectations are that most process models violate guidelines G3 and G4, while following guidelines G2 and G5. Lastly, guideline G7 will a have a few violations, but not enough to stand out.

\begin{table}[h]
	\centering
	\caption{Number of violations Per guideline}
	\label{ViolationsPerGuideline}
	\begin{tabular}{|c|c|c|}
		\hline
		& Total Violations & Percent of Total \\ \hline
		G2 & 2 & 6.45\% \\ \hline
		G3 & 1 & 3.23\% \\ \hline
		G4 & 10 & 32.26\% \\ \hline %TOREDO. I know it's 21-22
		G5 & 4 & 12.90\% \\ \hline
		G7 & 8 & 25.81\% \\ \hline
	\end{tabular}
\end{table}

Let's compare these conclusions with the results of our applied method, as show in table \ref{ViolationsPerGuideline}. According to it, our expectations for guidelines G2, G4, G5 and G7 do match the results. The results for guideline G3, though, is completely unexpected. 

Upon further analysis, we found a reason for this. Many process models of the collection have multiple pools or subprocesses, which, according to the notation, require new start and end events, causing a distortion in the number of events that a process model has. Therefore, we must take said distortion into account for our statistical analysis. Nevertheless, our plugin that verifies process models is doing this correctly.



\begin{table}[h]
	\centering
	\caption{Number of models per quantity of violations}
	\label{ModelsPerQuantityOfViolation}
	\begin{tabular}{|c|c|}
		\hline
		& Number of Models \\ \hline
		No violations & 12 \\ \hline
		One violation & 14 \\ \hline
		Two violations & 4 \\ \hline
		Three violations & 1 \\ \hline
	\end{tabular}
\end{table}

\section{CONCLUSIONS}\label{Conclusion}

\noindent Process models that follow process modeling guidelines are more likely to be understood by the process stakeholders. With the help of process modeling tools that support those guidelines, 

\subsection{Limitations}

\noindent 
%Note that the BPMN ontology is not worried with modeling the process dynamic behavior.

%\bibliographystyle{splncs03}
\bibliographystyle{apalike}
\bibliography{ArtigoVerificacao}
\end{document}